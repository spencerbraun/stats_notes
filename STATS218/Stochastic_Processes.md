---
title: Stochastic Processes II
date: 20200407
author: Spencer Braun
---

[TOC]

# Stochastic Processes II

## Introduction

* We have an experiment -> set of possible outcomes called the sample space $\Omega$
* An event is a subset of outcomes
* Axioms of probability
	* $0 \leq P(E) \leq 1$ for all events E (P(E) = probability of E)
	* $P(\Omega) = 1$
	* If $E_1,E_2,...$ disjoint events, then $P(\cup_{i=1}^\infty E_i) = \sum_{i=1}^\infty P(E_i)$. Disjoint means $E_i \cap E_j = \empty$ whenever $i\neq j$. Probability of the union is the sum of probabilities for disjoint events.
* RV is a function from $\Omega$ into $\R$. 
* A stochastic process is a collection of RVs $(X_t)_{t \in T} =X$. T can be $\{1,2,3,...\}$ or $[0,\infty)$; a sequence or continuum of RVs.

## Chapter 3: Renewal Theory
* A counting process for which the interarrival times are iid with an arbitrary distribution.
* Let $X_1,X_2,...$ be iid nonnegative RVs. Assume $P(X_n = 0 ) < 1$, there is some chance that our RV is nonzero. Let $\mu = E(X_n)$ where we allow $\mu$ to be $\infty$, but we have a well-defined expected value.
	* For example, if X is integer-valued and $P(X = k) = \frac{c}{k^2}$ where $c \sum \frac{1}{k^2} = 1$ then $E(X) = \infty$
* These variables are called **interarrival times**. Imagine clients arriving at a server, $X_i =$ time between $(i-1)th$ and ith arrival. Clients are immediately served (no queueing involved). Let $S_0= 0, \; S_n = \sum_{i=1}^n X_i$. Then $S_n=$ arrival time of the nth client.
* Let $N(t) = sup\{n: S_n \leq t\}$ (sup since theoretically there could be infinitely many) = number of clients arriving by time t. Maximum n such that the nth client has arrived by time t. 
* The stochastic process $(N(t))_{t \geq 0}$ is called a **renewal process**. Since the interarrival times are iid, it follows that at each renewal the process probabilistically starts over. Think of replacing lightbulbs - it stays on for a certain time before being replaced. N(t) is the number of bulbs you have to replace by time t. Plotted, we see piecewise constant function, jumping to the next integer i at each $S_i$. The times at which the jumps happen are random. A Poisson process is an example of a renewal process, limited to interarrival times with exponential random variables.
* Let $F_n(t) = P(S_n \leq t)$. This function is a CDF of a sum of RVs $S_n$, may not be easy to evaluate but can still be quite useful. 
* **N(t) / $S_n$ Equivalence** that $N(t) \geq n \iff S_n \leq t$; the number of variables up to the time t iff the nth customer has arrived by time t. Therefore $P(N(t) =n) = P(N(t) \geq n) - P(N(t) \geq n + 1) = P(S_n \leq t ) - P(S_{n+1} \leq t) = F_n(t) - F_{n+1}(t)$. If we know the CDF then we can calculate the probabilities for N(t).
* **Renewal function**: expected number of variables up to time t. The renewal function $m: [o, \infty)\rightarrow \R$ is defined as $m(t) = E(N(t) )=$ expected number of arrivals by time t.
* Generally we observe the renewal process for a while, observe the distribution of interarrival times then try to say something about what we can expect in the future.
* <u>**Theorem**</u> (Proposition 3.2.1, 3.2.2): $m(t) = \sum_{n=1}^\infty F_n(t)$ and $m(t) < \infty$ for all t.
  * In words, N(t), the number of renewals by time t, has finite expectation.
  * We can get F from the interarrival times, then calculate m and get the expected number of arrivals in some interval i in the future. m(t) is finite no matter what distribution we use. 
  * **Lemma 1**: Let X be a non-negative integer valued RV with $E(X) < \infty$ then $E(X) = \sum_{n=1}^\infty P(X \geq n)$
    * Proof: $E(X) = P(X = 1) + 2P(X=2) + 3P(X=3)$. Regrouping $=[P(X=1) + P(X=2) + ...] + [P(X=2) + P(X=3) + ...]+[P(X=3) + P(X=4) + ...] + ...$ This sum is equal to $\sum_{n=1}^\infty P(X \geq n)$. When summing non-negative quantities, we can rearrange the sum in any way and still get the same answer.
  * **Lemma 2** (Markov's Inequality): Let X be a non negative RV with $E(X) < \infty$ then for any $t > 0,\; P(X\geq t) \leq \frac{E(X)}{t}$
    * The LHS of the inequality is often much more complicated that the RHS, so this comes in handy
    * Proof: Let y be the following RV: $y = \begin{cases} 1 & if \;x \geq t \\ 0 & else \end{cases}$. Let Z = X/t. Then if X < t we have $y = 0 \leq Z$ since Z is a nonnegative RV. If $X \geq t$ then $y = 1 \leq x / t = Z$. So y is always $\leq Z \implies E(y) \leq E(Z)$. Finally, $E(y) = 0P(y = 0) + 1P(y=1) = P(X \geq t)$ and $E(Z) = \frac{E(X)}{t}$
  * **Lemma 3**: Let X be a non-negative RV st $P(X = 0) < 1$, then $E(e^{-X}) < 1$.
  	*  Note if X were always 0 then $e^{-X}$ would always be 1. 
    * Proof: Suppose $E(e^{-X}) = 1$ then $E(1-e^{-X}) = 0$. Since X is nonnegative then $1 - e^{-X} \geq 0$. So  $1 - e^{-X}$ is a nonnegative RV whose expectation is 0. So by Markov's Inequality, $P(1 - e^{-X} \geq t) \leq 0$ for any $t > 0 \implies P(1 - e^{-X} =0) = 1\implies P(X = 0)=1$. So we get a contradiction. Thus $E(e^{-X}) \neq 1$. But $e^{-X} < 1$ always so $E(e^{-X})$ cannot be > 1 thus  $E(e^{-X}) < 1$
  * **Lemma 4**: $m(t) < \infty$ for any t
    * Proof: $P(N(t) \geq n) = P(S_n \leq t)$ by above. $= P(e^{-S_n} \geq e^{-t}) \leq \frac{E(e^{-S_n})}{e^{-t}}$. Using the fact that X's are iid, then $ = e^t (E(e^{-X_1})^n) = e^tp^n$. By Lemma 1 $p = E(e^{-X_1})$. Then $m(t) = E(N(t)) = \sum_{n=1}^\infty P(N(t) \geq n) = \sum_{n=1}^\infty P(S_n \leq t = \sum_{n=1}^\infty) F_n(t)$. By the above $\sum_{n=1}^\infty P(N(t) \geq n) \leq e^t \sum_{n=1}^\infty p^n < \infty$ since $0 \leq p < 1$.
* Note the above also shows $E\left[N^{r}(t)\right]<\infty$ for all $t ,r \geq 0$
* Recall: $\mu = E(X_1) = E(X_2)=...$ which could be infinite.

### Limit Theorems

* **<u>Theorem</u>** (Proposition 3.3.1): With probability 1, $\underset{t\rightarrow \infty}{lim} \frac{N(t)}{t} = \frac{1}{\mu}$
  * As we take larger times, the number of arrivals goes to infinity. The only way in which $N(\infty)$, the total number of renewals that occurs, can be finite is for one of the interarrival times to be infinite (the next arrival never occurs).
  * $\underset{t\rightarrow \infty}{lim} \frac{N(t)}{t}$ is the rate at which N(t) goes to infinity. Per unit of time, how does N(t) change? $S_{N(t)}$ is the time of the last renewal up to time t and $S_{N(t) + 1}$ is the time of the first renewal after time t.
  * We will use the Strong Law of Large Numbers (SLLN) which says that $\frac{S_n}{n} \rightarrow \mu$ with probability 1. Means that the $P(\underset{t\rightarrow \infty}{lim} \frac{S_n}{n} = \mu) = 1$. This holds for mu finite or infinite.
  * **Lemma**: $\underset{t\rightarrow \infty}{lim} N(t) = \infty$ with probability 1.
    * Proof: The limit always exists because N is an increasing process. $\underset{t\rightarrow \infty}{lim} N(t) < \infty \iff X_n = \infty$  for some n. This is an integer valued process, so finite if it stops at some point. $P(X_n = \infty) = 0$ so $P(\underset{t\rightarrow \infty}{lim} N(t) < \infty) = p(\cup_{n=1}^\infty \{X_n = \infty\}) \leq \sum_{n=1}^\infty P(X_n = \infty) = 0$ (Probability of union is bounded by sum of probabilities). Fact: for any events $A_1,A_2,...\; P(\cup_{n=1}^\infty A_i )\leq \sum_{n=1}^\infty P(A_i)$
  * Proof: Note $S_{N(t)} \leq t < S_{N(t) + 1} $. The customer we count up to for N(t) arrives by t but the next customer must be after t by the definition of N(t). Recall $S_n$ is the arrival time of the nth client, N(t) = # of arrivals by time t. This implies $\frac{S_{N(t)}}{N(t) } \leq \frac{t}{N(t)} < \frac{S_{N(t) + 1}}{N(t)}$. $\frac{S_{N(t)}}{N(t)}$ is the average of the first N(t) interarrival times, and by using our SLLN fact that $N(t) \rightarrow \infty,\; \frac{S_n}{n} \rightarrow \mu$ as $n \rightarrow \infty$ we get  $\frac{S_{N(t)}}{N(t)} \rightarrow \mu$ as $t \rightarrow \infty$. This all happens with probability 1.
  * Then $\frac{S_{N(t)}}{N(t)} = \frac{N(t) + 1}{N(t)}\frac{S_{N(t)}}{N(t) + 1} \rightarrow 1\times \mu $ as $t \rightarrow \infty$. Therefore $\frac{t}{N(t)} \rightarrow \mu$ as $t \rightarrow \infty$
* Note $S_{N(t)}$ is the time of the last renewal prior to or at time t. Therefore $S_{N(t) + 1}$ is the time of the first renewal after time t.
* $\frac{1}{\mu}$ is the rate of the renewal process. By Prop 3.3.1, with probability 1 the long-run rate at which renewals occur is equal to $\frac{1}{\mu}$. 
* **Stopping Time**: Let $X_1,X_2,...$ denote a sequence of RVs. An integer-valued RV N is said to be a stopping time for the sequence if the event $\{N=n\}$ is independent of $X_{n+1},X_{n+2},...$ for all n and N is positive integer valued.  Said another way, the occurrence or non-occurrence of event $\{N=n\}$ is completely determined by the values of $X_1,X_2,...$ for every n. 
  * Note we allow $N = \infty$ also. Whether you stop or not, our evaluation of whether to stop is completely deterministic at time n.
  * Example: Let N = $min\{n: X_1+...+X_n \geq 5\}$. First n so the sum is at least 5. Then the event $\{N = n\}$ can be rewritten as the event $\{X_1 < 5, X_1+X_2 < 5,..., X_1+...+X_{n-1} < 5, X_1+...+X_{n} \geq 5\}$ . Up to n-1, our sum is always less than 5, then at n, the sum is greater or equal to 5. Rewritten this way, it is clear that the values of $X_1,...,X_n$ completely determine whether $\{N=n\}$ has happened or not, making N a stopping time for this sequence of X's.
* **<u>Theorem 3.3.2: Wald's Equation</u>**: If $X_1,X_2,...$ are iid RVs having finite expecations ($E|X_i|<\infty$), and if N is a stopping time for $X_1,X_2,...$ st $E(N) < \infty$ then $E\left[\sum_{i}^{N} X_{n}\right]=E[N ] E[X_1]$
  * Normally with a finite sum, the expectation would just move inside. Here we have a finite sum, but the range of the sum in random (see 217 for theorems on random sums). 
  * Fact: If $Y_1,Y_2,...$ are RVs st $\sum_{i=1}^\infty E|Y_i|  < \infty$ then $E(\sum_{i=1}^\infty Y_i) = \sum_{i=1}^\infty E(Y_i)$ (Consequence of dominated convergence theorem)
  * Proof of Wald: Let $I_n = \begin{cases} 1 & if \; N \geq n \\ 0 & else \end{cases}$ . Let $Y_n = X_n I_n = \begin{cases} X_n& if \; N \geq n \\ 0 & else \end{cases}$. Then $\sum_{n=1}^N X_n = \sum_{n=1}^\infty Y_n$ since $Y_n =0 $ for $ N \geq n$. We will show that $\sum_{n=1}^\infty E|Y_n| < \infty$ then we will conclude that $E(\sum_{n=1}^N X_n) = E(\sum_{n=1}^\infty Y_n) = \sum_{n=1}^\infty E(Y_n)$. Finally we will show that $\sum_{n=1}^\infty E(Y_n) = E(N)E(X_1)$
    * First note that the value of $I_n $ is determined by the occurrence or non-occurrence of the event $\{N < n\}$. This event $\{N < n\} = \{N =1\} \cup \{N =2\} \cup ...\cup \{N =n-1\}$. The occurrence or non-occurrence of each of the events on the right can be determined by the values of $X_1,...,X_{n-1}$. Therefore $I_n$ itself is a function of $X_1,..,X_{n-1}$.  Since these variables are independent, we conclude that $X_n,I_n$ are independent. 
    * So $E|Y_n| = E|X_nI_n| = E(|X_n||I_n|) = E|X_n| E(I_n) \overset{iid}{=} E|X_1| E(I_n)$. Then $=E|X_1|P(N \geq n)$. So in summation, $\sum_{n=1}^\infty E|Y_n| = E|X_1|\sum_{n=1}^\infty P(N \geq n) = E|X_1|E(N) < \infty$. 
    * Thus $E(\sum_{n=1}^N X_n) = E(\sum_{n=1}^\infty Y_n) = \sum_{n=1}^\infty E(Y_n)$
    * But again, $E(Y_n) = E(X_n I_n) \overset{\perp}{=} E(X_n)(I_n) = E(X_1) P(N \geq n) $ So $\sum_{n=1}^\infty E(Y_n) = E(X_1) \sum_{n=1}^\infty P(N\geq n) = E(X_1) E(N)$
  * Example: Stopping time $E(N) = \infty$ and Wald's equation fails. Let $X_1,...$ iid with $P(X_1=1) = P(X_1 = -1) = 1/2$. Let $S_n = \sum_{i=1}^n X_i$, $S_0 = 0$. let $N = min\{n: S_n = 1\}$. This is a random walk, looking for first time sum equal to 1. The event $\{N=n\} = \{S_1 \neq 1,....,S_{n-1} \neq 1, S_n = 1\}$, so N is a stopping time but Wald's equation does not hold because $E(N)E(X_1) = 0$ since $E(X_1) = 0$ but $E(\sum_{i=1}^N X_i) = E(S_N) = 1$ since $S_N = 1$. We can prove that the sum will definitely hit 1 at some point. 
  * Example: Let $X_1,X_2,...$ iid $P(X_i = 1) = P(X_i = -1) = 1/2$. Let $T = \begin{cases} 1 & if \; X_1 > X_1 + X_2 \\ 2 &  if \; X_1 \leq X_1 + X_2 \end{cases}$ and $S_n = \sum_{i=1}^n X_i$. Stop at 1 if somehow you know in the future this will yield you more money but continue to step 2 otherwise. T is not a stopping time since requires future knowledge. For all possible combinations of $X_1, X_2$, $E(S_T) = 1/2 \neq E(T)E(X_1) = 0$. Wald's lemma fails because T is not a stopping time.
* **<u>Theorem (Elementary Renewal Theorem)</u>**: $\underset{t \rightarrow \infty}{lim} \frac{m(t)}{t} = \frac{1}{\mu}$
  * In words, while the PP is the only renewal process whose renewal function $m(t)=\lambda t$ is exactly linear, all renewals are asymptotically linear.
  * Note that $ \frac{m(t)}{t} = E( \frac{N(t)}{t})$, so it looks like we have this result from above. However, $X_n \rightarrow a $ does not imply $E(X_n)\rightarrow a$ so we must prove this result.
  * This tells us about the behavior of the expected number of variables. Blackwell's renewal theorem is a more useful version of this. 
  * **Lemma**: $X_1,X_2,...$ iid interarrival times. Take any $ t \geq 0$ then $N(t) + 1$ is a stopping time with respect to the sequence of X's.
    * Proof: $\{N(t) + 1 = n\} = \{N(t) = n-1\} = \{X_1+...X_{n-1} \leq t, X_1+...X_{n} > t\}$. The nth variable happens after time t, but the n-1st variable happens before or at t.
  * **Corrolary** 3.3.3: $E(S_{N(t) + 1}) = \mu(m(t) + 1)$ if $\mu < \infty$
    * Proof: We have shown that $E(N(t) + 1) = E(N(t) + 1) = m(t) + 1 < \infty$. So by Wald's equation, $E(S_{N(t) + 1}) = E(\sum_{i=1}^{N(t) + 1} X_i) = E(N(t) + 1)E(X_1) = \mu(m(t) + 1)$
  * Proof: First we will show that $\underset{t \rightarrow \infty}{liminf} \frac{m(t)}{t} \geq \frac{1}{\mu}$. If $\mu < \infty$ then by the corr, $\frac{\mu(m(t) + 1)}{t} = \frac{E(S_{N(t) + 1 })}{t}$, the arrival time of the N(t) + 1 customer over t, which we know have to be bigger than 1 since the arrival always happens after t. But $S_{N(t) + 1} > t \implies E(S_{N(t) + 1} ) > t$ always. This implies $\frac{\mu(m(t) + 1)}{t} > 1 \implies \underset{t \rightarrow \infty}{liminf} \frac{m(t)}{t} \geq \frac{1}{\mu}$. If $\mu = \infty$, then this is trivially true.
  	* Next step: show $\underset{t \rightarrow \infty}{limsup}   \frac{m(t)}{t} \leq \frac{1}{\mu}$. Take some constant $M > 0$, then define $\bar{X}_n = \begin{cases} X_n & if \; X_n \leq M \\ M & if X_n > M\end{cases}$. $\bar{S_n} = \sum_{i=1}^n \bar{X_i},\; \mu_M = E(\bar{X}_1),\; \bar{N}(t) = sup \{n: \bar{S_n} \leq t \},\; \bar{m}(t) = E(\bar{N}(t))$. We can note that $\bar{S}_{\bar{N}(t) + 1} \leq t + M$- if the interarrival times are bounded by M, the arrival time of the customer that arrives right after t cannot exceed t by more than M. This is a nice result of truncation - we are supplied with an upper bound. Recall $\bar{N}(t) + 1$ is a stopping time and $E(\bar{N}(t) + 1 ) = \bar{m}(t) + 1 < \infty$ so by Wald, $(\bar{m}(t)+1) \mu_{M} \leq t+M \implies \frac{\bar{m}(t)}{t}+\frac{1}{t} \leq \frac{t+M}{t \mu_M}$. Take limsup of both sides $\implies \limsup _{t \rightarrow \infty} \frac{\bar{m}(t)}{t} \leqslant \frac{1}{\mu_{M}}$. 
  	* Note that the nth customer in the new process always arrives before the nth customer in the old process since the interarrival times are equal or smaller. The new process has every interrival time equal or less than the old process for all n. Thus $\bar{S}_n \leq S_n,\; \forall n$ and so $\bar{N}(t) \geq N(t)$ for all t. This implies that $\bar{m}(t) \leq m(t) \implies \underset{t \rightarrow \infty}{limsup} \frac{m(t)}{t} \leq  \underset{t \rightarrow \infty}{limsup} \frac{\bar{m}(t)}{t} \leq \frac{1}{\mu_M} $. The LHS does not depend on M, so the proof will be complete if we can show that $\mu_M \rightarrow \mu$ as $M \rightarrow \infty$. This follows by a measure theoretic results known as the monotone convergence theorem. 

### Key Renewal Theorem and Applications

* A nonnegative RV X is said to be **lattice** if there exists $d \geq 0$ st $\Sigma_{n=0}^{\infty} P\{X=n d\}=1$ - it only takes on integral multiples of some nonnegative number d. In other words, $X \in \{0, d, 2d, ...\}$ with probability 1. The largest d is said to be the **period** of X. If X is lattice and F is the distribution function of X, then we say F is lattice. 
* **<u>Blackwell's Theorem</u>**: (i) If F is not lattice, then $\underset{t \rightarrow \infty}{lim} \;m(t+a)-m(t) = a / \mu$ for all $a \geq 0 $.  (ii) If F is lattice with period d, then E(number of arrivals at nd) $\rightarrow d/\mu$ as $n \rightarrow \infty$
  * F is the CDF of the interarrival times.
  * If F is not lattice (say X continuous), the expected number of renewals in an interval of length $a$ far from the origin is approx $a / \mu$ - the further away from the origin we are, the less influence initial effects will have. 
  * When F is lattice with period d, then the limit $g(a) \equiv \lim _{t \rightarrow \infty}[m(t+a)-m(t)]$ cannot exist. Renewals can only occur at integral multiples of d, so the expected number of renewals in an interval far from the origin depends on how many points of $nd$ it contains. If interarrivals are always positive, then part (ii) says $\lim _{n \rightarrow \infty} P\{\text { renewal at } n d\}=\frac{d}{\mu}$ 
  * For a PP, m(t) is exactly linear equal to $\lambda t$ , so its derivative wrt t is always $\lambda$. In general, m(t) may start out wiggly, but for very large t, m(t) will look approximately linear.
* Let h be a function defined on $[0, \infty) \rightarrow \R$. For any a > 0, le $\underline{h}_n(a)$ be the supremum and $\overline{h}_n(a)$ the infinum of h(t) over the interval $(n-1)a \leq t \leq na$. We say that h is directly Riemann integrable if $\sum_{n=1}^\infty \overline{h}_n(a)$ and $\sum_{n=1}^\infty \underline{h}_n(a)$ are finite for all a > 0. Basically these sums quickly go to zero for these sums to be finite. Also $\lim _{a \rightarrow 0} a \sum_{n=1}^{\infty} \bar{h}_{n}(a)=\lim _{a \rightarrow 0} a \sum_{n=1}^{\infty} h_{n}(a)$. A sufficient **condition for h to be directly Riemann integrable** is that 
  * $h(t) \geq 0,\; \forall t \geq 0$  - non negative
  * h(t) is nonincreasing
  * $\int_{0}^{\infty} h(t) d t<\infty$
* **<u>Key Renewal Theorem</u>**: If F is not lattice and if h(t) is directly Riemann integrable then $\lim _{t \rightarrow \infty} \int_{0}^{t} h(t-x) d m(x)=\frac{1}{\mu} \int_{0}^{t} h(t) d t$ where $m(x)=\sum_{n={1}}^{\infty} F_{n}(x)$ and $\mu=\int_{0}^{\infty} \overline{F}(t) d t$. 
	* Aside: $\int ... dm(x)$ is the Riemann-Stieltjes integral wrt m. Usual Riemann integral $\int_a^b f(x) dx = lim \sum_{i=1}^n f(x_i)(x_{i+1} - x_i)$ as you take finer and finer partitions $x_0,...,x_n$ of [a,b]. The RS integral $\int_a^b f(x) d g(x)$ is the limit of $\sum_{i=1}^n f(x_I)(g(x_{i+1}) - g(x_i))$. If g is differentiable, then since $g(x_{i+1}) - g(x_i) \approx g^\prime(x_i)(x_{i+1} - x_I)$ we get $\int_a^b f(x) d g(x) = \int_a^b f(x) g^\prime(x) dx$
    * Note $\int_{a}^{b} f(x) \mathrm{d} g(x)=f(b) g(b)-f(a) g(a)-\int_{a}^{b} g(x) \mathrm{d} f(x)$
  * Blackwell and KRT can be shown to be equivalent. 
  * Intuition: If m is differentiable, $ \int_{0}^{t} h(t-x) d m(x) =  \int_{0}^{t} h(t-x) m^\prime(x) dx$. Now h(t-x) is very small unless x is close to t since h decays rapidly (see conditions on h). So we can ignore the part of the integral where x is far away from t. OTOH, if t is large and x is close to t, Blackwell's thm implies that $m^\prime(x) \approx \frac{1}{\mu}$. So if x close to t and large, $\int_{0}^{t} h(t-x) m^\prime(x) dx \approx \int_0^t h(t-x) \frac{1}{\mu}dx = \frac{1}{\mu}\int_0^t h(y) dy \approx \frac{1}{\mu}\int_0^\infty h(y) dy $ if t large.
  * KRT is used when one wants to compute the limiting value of g(t), so probability or expectation at time t. Generally derive an equation for g(t) by conditioning on the time of the last renewal prior to t, which yields equations of the form $g(t)=h(t)+\int_{0}^{t} h(t-x) d m(x)$. 
  * **Lemma 3.4.3**: $P\left\{S_{N(t)} \leq s\right\}=\overline{F}(t)+\int_{0}^{t} \overline{F}(t-y) d m(y)$ for $t \geq s \geq 0$

### Alternating Renewal Processes

* Example: Lightbulb replacements. Want to know the distribution of the amount of time that a lightbulb remains lit. Say you have an inspector that comes in over long periods of time and records how long the bulb has been on. If most are very short lived but a few will live for a while, the inspector will not see the short lived bulbs typically - he will see the longer lasting bulbs since they are installed the majority of the time (the others are replaced quickly, despite their majority). KRT can make this distribution precise.
* The lifetime observed at time t tends to be longer than a random interval between points, Xn. There is length-biased sampling.
* Basic formula: Let X be nonneg RV with cdf F and let A be an event. Then $P(A \cap \{X \leq s\}) = \int_0^s P(A|X=t)dF(t)$. 
	* Proof sketch: $P(A \cap \{X \leq s\}) = \sum_{i=1}^n P(A  \cap \{s_i < X \leq s_{i+1}\})$ where $0 = s_0 \leq s_1 \leq ...\leq s_n =s$. This can be written as $  \sum_{i=1}^n P(A  | s_i < X \leq s_{i+1})P(s_i < X \leq s_{i+1})$ and $P(s_i < X \leq s_{i+1}) = F(s_{i+1} - F(s_i))$. The $s_i$ are finer and finer partitions - x lies in a small interval so $P(A  | s_i < X \leq s_{i+1}) \approx P(A  |X= s_i )$ so the sum approaches this integral. When $F^\prime = f$, then $P(A \cap  \{X \leq s\}) = \int_0^s P(A|X= t) f(t) dt$ generally.
* Using this idea, let's define some distributions. Consider process of replacing lightbulbs, let $A(t) = t - S_{N(t)} = $ age of the bulb that is on at time t, since $S_{N(t)}$ is the time of the last replacement. Then $Y(t) = S_{N(t) + 1} - t = $ residual life of the bulb that is on at time t. Then $X_{N(t) + 1} = $ total lifetime of the bulb that is on at time t. Therefore $X_{N(t) + 1} = A(t) + Y(t) $. On a numberline, have a time t with $S_{N(t)}$ to the left and the space between them is A(t), while the space from t to $S_{N(t) + 1}$ to the right is Y(t). The gap from $S_{N(t)}$  to $S_{N(t) + 1}$ is  $X_{N(t) + 1}$. 
	* We will compute the limiting distribution of A(t), Y(t), and $X_{N(t) + 1}$ as $t \rightarrow \infty$. A(t) we can calculate from data and use renewal theory for the other distributions.
	* The expected number of arrivals in a short period of time far in the future is $\frac{1}{\mu}$ times the length of the interval
* **Distribution of A(t)**: $P(A(t) \leq x) = ?$ for $0 \leq x < t$. This event $\{A(t) \leq x\}$ is the disjoint union of the events $\{t - x \leq S_n \leq t, S_{n+1} > t\}, n = 1,2,...$. If this event happens then these other events must happen; and if one of these events happens then $A(t) \leq x$. The nth event is that the lightbulb burns out between $t-x,\; t $ and the n+1st lightbulb burns out after t. 
	* $A(t) \leq x$ means that exactly one of the following must have happened: either the first lightbulb goes out between time t-x and t $S_1 \in [t-x, t], \; S_2 > t$ and the second lightbulb goes out after t OR the second lightbulb out between t - x and t and third goes out after t  $S_2 \in [t-x, t], \; S_3 > t$...etc. Disjoint events
  * So $P(A(t) \leq x) = \sum_{n=1}^\infty P(t - x \leq S_n \leq t, S_{n+1} > t)$ - the probability of A(t) is the same as exactly one of these events has happened. 
  * Then $P(t - x \leq S_n \leq t, S_{n+1} > t) = \int_{t-x}^t P(S_{n+1} > t | S_n = y) d F_n(y)$, recalling $F_n$ is CDF of $S_n$. (Eg. if $F_n$ differentiable and derivative is the pdf of $S_n$ then $P(t-x \leq S_n \leq t, S_{n+1} > t) = \int_{t-x}^t P(S_{n+1} > t | S_N = y) f_n(y) dy$. This is a generalization of that.) 
  * So we can write $P(A(t) \leq x ) = \sum_{n=1}^\infty \int_{t-x}^t P(S_{n+1} > t | S_n = y) dF_n(y)$.
  * General measure-theoretic results imply that the infinite sum can be taken inside the integral: $P(A(t) \leq x ) = \int_{t-x}^t  \sum_{n=1}^\infty P(S_{n+1} > t | S_n = y) dF_n(y)$.
  * Then (for $y \leq t$) $ P(S_{n+1} > t | S_n = y)  = P(x_{n+1} > t - y | S_n = y) =  P(x_{n+1} > t-y )$ since $X_{n+1}$ and $S_n$ are independent, so conditioning goes away. $P(x_{n+1} > t-y )= \bar{F}(t-y)$ where $\bar{F}(n) = 1 - F(n)$ and F is the CDF of the interarrival times.
  * Therefore $P(A(t) \leq x) = \int_{t-x}^t\bar{F}(t-y) \sum_{n=1}^\infty dF_n(y)$. In a R-S integral $\int f(x) d g(x)+\int f(x) d h(x) = \int f(x) d(g+h)(x) = \int f(x) dw(x)$ for $w = g+h$. Extends to infinite sums under conditions. We know that $m(t) = \sum_{n=1}^\infty F_n(t)$. Thus $\sum_{n=1}^{\infty} d F_{n}(y)=\operatorname{dm}(y)$.
	* Then $P(A(t) \leqslant x)=\int_{t-x}^{t} \bar{F}(t-y) d m(y) = \int_0^t h(t-y)dm(y)$. Define $h(u) = \begin{cases} \bar{F}(u) & if \; u \leq x \\ 0 & else \end{cases}$. Since y < t - x implies t - y > x implies h(t-y) = 0.
	* Returning to the Key Renewal Thm, the h that we defined satisfies the sufficient conditions for KRT, so we can invoke the KRT to get the limit of our probability. h is nonnegative, non increasing, and integral is finite. Assume F is non lattice. 
	* From KRT we get $\lim _{t \rightarrow \infty} P(A(t) \leqslant x) = \frac{1}{\mu} \int_{0}^{\infty} h(u) d u = \frac{1}{\mu} \int_{0}^{x} \bar{F}(u) d u$. Therefore the limiting CDF of A(t) as $t \rightarrow \infty$ is given by $G(u) = \frac{1}{\mu} \int_{0}^{x} \bar{F}(u) d u$. By FTC, this is a differentiable function: $G^\prime(x) = \frac{1}{\mu}\bar{F}(x) =  \frac{1}{\mu}(1 - F(x))$. Why is this a valid PDF? Because $\mu = E(X_1) = \int_0^\infty P(X_1 > t ) dt = \int_0^\infty \bar{F}(t) dt$ (we did not prove but is a fact: we can write expectations as infinite integrals). 
* Example: $X_i \sim exp(\lambda)$ (we have a PP). Then $F(x) = 1 - e^{-\lambda x}$ and $\mu =\lambda$. Then $G(x) = \lambda e^{-\lambda x}$, as $t \rightarrow \infty$  then $A(t) \sim Exp(\lambda)$.
	* If instead $X_i \sim Unif(0,1)$ then $F(x) = x ,\; x \in [0,1],\; \mu = 1/2$. Then $G(x) = 2(1-x)$. Our pdf is then more likely to be close to 0 than towards 1 - not uniformly distributed.
* **Limiting Distribution of Y(t)**, the residual lifetime of the bulb that is on at time t.
	* Want to understand $P(Y(t) \leq x) = ?$. Events $\{Y(t) \leq x\}$ is the union of disjoint events $\left\{S_{n} \leq t, \quad t<S_{n+1} \leqslant t+x\right\} \quad n=0,1,2,...$. Either the first lightbulb goes off between t and t + x OR second lightbulb goes off between t and t + x and first goes off up to t...etc. This means $P(Y(t) \leq x) = \sum_{n=0}^\infty P\left(S_{n} \leq t, t<S_{n+1} \leqslant  t+x\right) = P(t < S_1 \leq t + x) + \sum_{n=1}^\infty \int_0^t P(t < S_{n+1} \leq t + x | S_n=y)d F_n(y)$. 
	* So the first term $ = \bar{F}(t) - \bar{F}(t + x)$ for $\bar{F}(y) = P(X_1 > y)$. Then in total have $\bar{F}(t) - \bar{F}(t + x) + \sum_{n=1}^\infty \int_0^t P(t-y < x_{n+1} \leq t + x - y | S_n=y)dF_n(y)$. Note $S_1 = X_1$ and $S_{n+1} = S_n + X_n$. So $= \bar{F}(t) - \bar{F}(t + x) + \sum_{n=1}^\infty \int_0^t P(t-y < x_{n+1} \leq t + x - y )dF_n(y)$ and by iid X we have $P(t-y < x_{n+1} \leq t + x - y ) = \bar{F}(t-y)-\bar{F}(t+x-y)$.
	* Then moving the sum inside $= \bar{F}(t) - \bar{F}(t + x) + \int_0^t  \bar{F}(t-y)-\bar{F}(t+x-y) \sum_{n=1}^\infty  dF_n(y)$ and noting $\sum_{n=1}^\infty  dF_n(y) = dm(y)$: $P(Y(t) \leq x)=  \bar{F}(t) - \bar{F}(t + x)  + \int_0^t h(t-y)dm(y)$ where $h(u) =  \bar{F}(u) - \bar{F}(u + x)$.  Notice that $\bar{F}(t) \rightarrow 0, \; t \rightarrow \infty$
	* So by KRT, $\underset{t \rightarrow \infty}{lim} P(Y(t) \leq x) = \frac{1}{\mu}\int_0^\infty h(u) du =  \frac{1}{\mu}\int_0^\infty ( \bar{F}(u) - \bar{F}(u + x)) du$. The splitting into two: $=   \frac{1}{\mu}[\int_0^\infty\bar{F}(u) du - \int_0^\infty \bar{F}(u + x) du] = \frac{1}{\mu}[\int_0^\infty\bar{F}(u) du - \int_x^\infty \bar{F}(y) dy]$. So in total get in the limit $\underset{t \rightarrow \infty}{lim} P(Y(t) \leq x)=  \frac{1}{\mu} \int_0^x \bar{F}(u)du$. This is the same limit as the one we got for A(t)!
	* The age and the residual time have the same distribution. For our uniform example, both the age and the residual time are closer to 0 than to 1!
	* If we look backwards in time, the time between successive events is still independent with distribution F - we have a renewal process in both forward and backward directions.
* **Limiting distribution of $X_{N(t) + 1}$ ** - the total lifetime of the bulb that is on at time t.
	* Look at event $\left\{X_{N(t)+1}>x\right\}$ is the disjoint union of the events $\{\left\{S_{n} \leq t, \quad S_{n+1}>t, X_{n+1}>x\right\}\}$ for n = 0, 1, 2.... 
	* Taking $t > x \geq 0$,  $P(x_{N(t)+1}>x) = \bar{F}(t) + \sum_{n=1}^\infty P(S_{n} \leqslant t, S_{n+1}>t, X_{n+1} > x)$ Then $ = \bar{F}(t) + \sum_{n=1}^\infty \int_0^t P(S_{n+1}>t, X_{n+1} > x|S_n =y) dF_n(y)$.
	* Suppose $S_n = y$ - there are two cases to consider. (1) $t-x \leq y \leq t$ and (2) $y < t-x$. Case 1: in this case, $x_{n+1} > x \implies S_{n+1} > t$ and then $P(S_{n+1}>t, X_{n+1} > x|S_n =y)  = P(X_{n+1} > x|S_n =y) \overset{\perp}{=} P(X_{n+1} > x) = \bar{F}(x)$.  In Case 2: in this case $S_{n+1} > t \implies x_{n+1} > x$. So $P(S_{n+1}>t, X_{n+1} > x|S_n =y) = P(S_{n+1}>t |S_n =y)  = P(X_{n+1} > t-y|S_n =y)  \overset{\perp}{=}P(X_{n+1} > t-y) = \bar{F}_n(t-y)$.
	* Combining these cases, you get $P(x_{N(t)+1}>x)  =   \bar{F}(t) +  \int_0^t \sum_{n=1}^\infty P(S_{n+1}>t, X_{n+1} > x|S_n =y) dF_n(y) =  \bar{F}(t)  +  \int_0^t h(t-y) \sum dF_n(y) $ where $\sum dF_n(y)  = dm(y)$. Here $h(u) = \begin{cases} \bar{F}(x) & if \; u \leq x \\ \bar{F}(u) & if \; u > x  \end{cases}$. 
	* By KRT, $\underset{t \rightarrow \infty}{lim} P\left(X_{N(t)+1}>n\right)=\frac{1}{N} \int_{0}^{\infty} h(u) d u = \frac{x \bar{f}(u)}{\mu} + \frac{1}{\mu}\int_x^\infty \bar{F}(u) du$. 
	* Simplifying using integration by parts: $\int_x^\infty y dF(y) = -\int_x^\infty yd\bar{F}(y)$ (Think of this  RS as integrating wrt the derivative of f). $=[-y\bar{F}(y)]_x^\infty + \int_x^\infty\bar{F}(y)dy = x\bar{F}(x) +  \int_x^\infty\bar{F}(y)dy$ . Thus $\underset{t \rightarrow \infty}{lim} P\left(X_{N(t)+1}>n\right) =  \frac{1}{\mu} \int_x^\infty y dF(y)$. This is known as the size biased distribution of F. If F has pdf f, then the size biased distribution has pdf $\frac{1}{\mu}xf(x)$ (Since it has expectation $\mu$, dividing by $\mu$ gives us a pdf that integrates to one). 
	* The lightbulbs have some distribution to their lifetimes, but if you look at the renewal process they are only replaced when they go out. At some large time t, the lightbulb in place will have a distribution biased towards the right - longer than the typical lightbulb. Why? If some lightbulbs live short and some long, some time in far future it is more likely that you will see a long lifed bulb than short.
	* This has relevance to survey sampling. Want some distribution of family income in a population, select some phone numbers at random and survey them. The distribution will be the size biased distribution of the actual distribution - larger families will have more representatives - a family of ten people is more likely to get a call than a single person.

## Chapter 6: Martingales

* A stochastic process $\{Z_n\}_{n \geq 1}$ is called a martingale if 
	* $E|Z_n| < \infty$ for all n
	* $E(Z_{n+1}|Z_1,...,Z_n) = Z_n$ for all n
* Let $f(Z_1,...,Z_n) = E(Z_{n+1}|Z_1=z_1,...,Z_n=z_n) $ then the RV $f(Z_1,...,Z_n) $ is denoted by $E(Z_{n+1}|Z_1,...,Z_n)$.
* Generalized version of a fair game - if $Z_n$ is a gambler's fortune after the nth gamble, then his fortune after the (n+1)st gamble is equal to his fortune after the nth gamble: $E\left[Z_{n+1}\right]=E\left[Z_{n}\right]= E\left[Z_{1}\right]$.
	* Sums of zero mean random variables, products of mean 1 random variables.
* Example: Let $X_1,...$ be independent RVs with $E(X_i)=0$ and $E|X_i| < \infty$. Let $S_n = \sum_{i=1}^n X_i,\; S_0 = 0$ Then $\{S_n\}_{n \geq 0}$ is a martingale
	* Proof: $E(S_{n+1} | S_0 = s_0,...,S_n=s_n ) = E(S_{n+1} | x_1= s_1, X_2  = s_2 - s_1,...,X_n=s_n - s_{n-1} )$. Then $=E(X_{n+1} + s_n | x_1= s_1, X_2  = s_2 - s_1,...,X_n=s_n - s_{n-1} )$. By independence, $E(X_{n+1}| x_1= s_1, X_2  = s_2 - s_1,...,X_n=s_n - s_{n-1} ) = E(X_{n+1}) = 0$. Thus $E(S_{n+1} | S_0 = s_1,...,S_n=s_n ) = s_n$. Therefore  $E(S_{n+1} | S_0 ,...,S_n) = S_n$. Also $E|S_n| \leq E|X_1| + ... + E|X_n| < \infty$ by triangle ineq. Thus $\{S_n\}_{n \geq 0}$ is a martingale
* Example: Polya's Urn Model. An urn contains one white ball and one black ball. Pick a ball at random. Replace it back to the urn together with an extra ball of the same color. Repeat. Let $X_n$ be the proportion of white balls at time n (start at time 1). We know $X_1 = 1/2$, and at any time the number of balls = n + 1. Claim: $\{X_n\}_{n \geq 1}$ is a martingale. 
	* Proof: Note $E|X_n| \leq 1$ since a proportion. Now $E(X_{n+1} | X_1 = x_1,...,X_n = x_n) = P($picking white ball$| X_1=x_1,...,X_n=x_n) + P($picking black ball$| X_1=x_1,...,X_n=x_n) $. The first prob is $\frac{(n+1)X_n + 1}{n+2}$ - the number of white balls at time n is $(n+1)x_n$. Then the latter is $\frac{(n+1)x_n}{n+2}$. So this expression is $=X_n\frac{(n+1)X_n + 1}{n+2}+ (1-X_n)\frac{(n+1)X_n + 1}{n+2}$. This simplifies to $\frac{(n+2)X_n}{n+2} = X_n$. Thus $E(X_{n+1} | X_1,...,X_n) = X_n$ and we have a martingale.
* A **bounded martingale** will always converge to a limit - which is what we have with Polya. With simulation we will see some volatility in the proportion but over time may look like convergence to a limit. But if you run the experiment again, it will also converge, but not necessarily to the same proportion - the limit itself is a random variable.
* Let $\{Z_n\}_{n\geq1}$ be a martingale. Recall that a RV N is a called a stopping time wrt the sequence if for any n, the occurrence or non-occurrence of the event $\{N=n\}$ is determined by the values of $Z_1,...,Z_n$. 
* **<u>Martingale Stopping Theorem</u>** (Simple Version): Let  $\{Z_n\}_{n\geq1}$ be a martingale and N be a stopping time st there is some n for which $N \leq n$ always (bounded by some deterministic number). Then $E(Z_N) = E(Z_1)$. 
	* Note that N is random, so $Z_N$ is not one of the RVs $Z_1,...,Z_n$. What is $Z_N$? Recall that there is an experiment with a set of outcomes $\Omega$ st all of our RVs are functions from $\Omega \rightarrow \R$. The RV $Z_N$ is defined as $Z_N(\omega) := Z_{N(\omega)}(\omega)$ - this is called a **stopped random variable**. For example, if for some $\omega,\; N(\omega) = 5,\; Z_{5}(\omega) = 0.1$ then $Z_N(\omega) = Z_{N(\omega)}(\omega ) = Z_{5}(\omega)$
	* This may not be very useful on its own since many Martingales are not bounded. But combined with other results will be more useful.
	* Proof of MST: Claim: $E(Z_n | Z_1,...,Z_k) = z_k$ for any $1 \leq k \leq n$. Proof: $E(Z_n | Z_1=z_1,...,Z_{n-2}=z_{n-2})  = \sum_{j} E(Z_n | Z_1=z_1,...,Z_{n-2}=z_{n-2}, Z_{n-1} = j)P(Z_{n-1} = j|  Z_1=z_1,...,Z_{n-2}=z_{n-2})  $. So given the first n-2, we can write this decomposition via law of total probability. Then since martingale, can say $= \sum_{j} j P(Z_{n-1} = j|  Z_1=z_1,...,Z_{n-2}=z_{n-2})  =  E(Z_{n-1} | Z_1=z_1,...,Z_{n-2}=z_{n-2}) = z_{n-2}$. Proceed by induction. Notice, we used that we have a martingale to take a claim from n-1 to n-2, allowing induction to show its generality for k in our range. 
	* Next claim: For any $1 \leq k \leq n$ let $Y_k = \begin{cases} 1 & if \; N = k \\ 0 & else \end{cases}$. Then $E(Z_nY_k) = E(Z_kY_k)$. Proof: Note that $Y_k$ is a function of $Z_1,...,Z_k$ since N is a stopping time (determined by these Z's). So given $Z_1=z_1,...,Z_k = z_k$, $Y_k$ is just a constant, say $y_k$. Thus $E(Z_nY_k | Z_1=z_1,...,Z_k = z_k ) = y_kz_k$ by the first claim, using the Martingale property. Thus $E(Z_nY_k) = \sum_{Z_1,...,Z_k} E(Z_nY_k | Z_1=z_1,...,Z_k = z_k )  P(Z_1=z_1,...,Z_k = z_k)$ and then $ =  \sum_{Z_1,...,Z_k} z_ky_k P(Z_1=z_1,...,Z_k = z_k) = E(Z_kY_k)$ (since the expecation of a function of an RV is that function times its pdf, summed over all possibilities).
	* Completing the proof: Note that N must always take one of the values 1,2,...,n. Thus $\sum_{k=1}^n Y_k = 1$, since one point in the sample space gives value 1 and the rest 0. Therefore $E(Z_n) = E(Z_n \sum_{k=1}^n Y_k) = \sum_{k=1}^n E(Z_nY_k) = \sum_{k=1}^n E(Z_kY_k)  =  E(\sum_{k=1}^nZ_kY_k)  = E(Z_N)$ since for any $\omega \in \Omega,\; \sum_{k=1}^nZ_k(\omega)Y_k(\omega) = Z_j(\omega)$ if $Y_j(\omega = 1$ and $Y_k(\omega) = 0$ for $j \neq k$. In other words $\sum_{k=1}^nZ_k(\omega)Y_k(\omega)  = Z_{N(\omega)(\omega)} = Z_N(\omega)$. 
	* Thus $E(Z_n) = E(Z_N)$. But we also know by the first claim that $E(Z_n | Z_1 = z_1) = z_1$. Then $E(Z_n) = \sum_{z_1} E(Z_n | Z_1 = z_1)P(Z_1 = z_1) =  \sum_{z_1} z_1P(Z_1 = z_1)  = E(Z_1)$. Therefore $E(Z_N) = E(Z_1)$. 
* In a fair game, if a gambler uses a stopping time to decide when to quit, then his expected final fortune is equal to his expected initial fortune. We can view the MST as another proof of Wald's equation. Given the Wald conditions, $Z_{n}=\sum_{i=1}^{n}\left(X_{i}-\mu\right)$ is a Martingale and therefore $E\left[Z_{N}\right] = E\left[\sum_{i=1}^{N} x_{i}\right]-E[N] \mu$. 
* Example: Let $X_1,... $ be independent mean 0 RVs and  $S_n = \sum_{i=1}^n X_i$ We know that  $\{S_n\}_{n \geq 0}$ is a martingale. Let $T = min \{n = S_n \notin (a,b)\},\; a < 0 < b$. First time it leaves an interval like this (fixed a,b).  
	* Easy to see T is a stopping time. $\{T=n\} = \{S_0 \in (a,b), S_1 \in (a,b),..., S_{n-1} \in (a,b), S_n \notin (a,b)\}$. Completely determined by past events, so T is a stopping time but not a bounded stopping time. Simple MST does not apply here as a note.
	* Suppose $X_i$s are $\pm 1$ with probability 1/2 each. Then $S_n$ is a simple symmetric random walk. Suppose also that a,b are integers then at time T, the walk is either at a or at b. So $S_T$ can only take one of two values - a or b. So $S_T(\omega) = S_{T(\omega)}(\omega)$. At that time $T(\omega)$ the walk is either a or b.
* Computing a mean time until a given pattern occurs: sequence of iid discrete RVs observed sequentially, expected number until a specified pattern is observed. 
	* Let N denote the time until the sequence of length X appears. At the end of day N, each of the gamblers 1,...,N-X would have lost 1 unit, gambler N-(X-1) would have won the full better sequence, and the rest to N win depending on how the sequence repeats itself. 
* **<u>Dominated Convergence Theorem</u>**: Suppose that$\{X_n\}_{n \geq 1}$ is a sequence of RV converging to a limit RV X. Suppose that there exists a RV Y with E|Y| finite st $|X_n| \leq |Y|,\;\forall n$. Then $\underset{n \rightarrow \infty}{lim} E(X_n) = E(X)$. Special case: **bounded convergence theorem** where Y is a constant.
* **<u>Monotone Convergence Theorem</u>**: If $X_n$ is a sequence of non-negative RVs *increasing* to a RV X, then the $\underset{n \rightarrow \infty}{lim} E(X_n) = E(X)$. (Alternative version: If $Y_1,Y_2,...$ are non-neg RVs then $E(\sum_{i=1}^\infty Y_i) = \sum_{i=1}^\infty E(Y_i)$)
* Let $Z_1,Z_2,...$ be any sequence of RVs, let N be a stopping time for this sequence. Take any $n \geq 1$. Define a new RV $N_n$ as $N_n = \begin{cases} N & if \; N \leq n \\ n & if \; N > n \end{cases}$. Claim: $N_n$ is a stopping time (for any n), producing sequence of stopping times. 
	* Proof: Take any k. If $k < n$ then the event $\{N_n=k\}$ is the same as the event $\{N = k\}$ and so it's occurrence or non-occurrence is determined by the values of $Z_1,...,Z_k$. Why? This can only happen is if N = k, ie. strictly less than n. If $k > n$ then $\{N_n=k\}$ is an impossible event and is therefore vacuously determined by $Z_1,...,Z_k$. Finally, if k = n, then $\{N_n=k\} = \{N_n=n\}$, is the same as $\{N \geq n\}$. But $\{N \geq n\} = \{N < n\}^C =\{N = 1\}^C \cap \{N =2\}^C \cap ... \cap \{N = n -1\}^C$ . Occurrence or non-occurrence of each of these events can be determined by the values of $Z_1,...,Z_{n-1}$. Thus $\{N_n=n\}$ is also determined by  $Z_1,...,Z_{n}$.
* **Lemma**: If $P(N < \infty)  =1$ (recall stopping times can be infinite), then the sequence $N_n$ converges to N as $n \rightarrow \infty$. Moreover $N_1 \leq N_2 \leq ...$ (an increasing sequence).
	* Proof: The inequality $N_n \leq N_{n+1}$ is simple. If $N \leq n$ then $N_n = N_{n+1} = N$. If $N \geq n + 1$ then $N_n = n, \; N_{n+1} = n+1$ and so $N_n \leq N_{n+1}$. Next suppose that $N(\omega) < \infty $ for some $\omega \in \Omega$. Say $N(\omega) = k$ then $N_n(\omega) = n $ for n < k and $N_n(\omega)  = k $ for $n \geq k$. Therefore $\underset{n \rightarrow \infty}{lim} N_n(\omega) = k = N(\omega)$. Thus if $P(N < \infty) = 1$ then $ P(\underset{n \rightarrow \infty}{lim} N_n =N) = 1$.
	* Say you decide to buy a stock if index hits a certain value - this is a stopping time. Say instead you buy a stock if index hits a certain value but within a 10 day window, if doesn't hit by day 10 you buy the stock anyway - this is $N_n$.
	* Note for any n, $N_n$ is a bounded stopping time, because $N_n \leq n$. This allows us to use the MST.
* **<u>Theorem: Better MST</u>**. Let $Z_1,Z_2,..$ be a martingale. Let N be a stopping time for this sequence. Suppose that there is a constant C such that $|Z_n| \leq C$ whenever $n \leq N$ (the sequence may not be bounded, but you know there is a non random constant C, before you hit the stopping time the abs val of the sequence is bounded by C). Assume that $P(N < \infty) = 1$. Then $E(Z_N) = E(Z_1)$
	* With the stock buying behavior - the index can hit any value, but we have set a price level at which we buy and then hit our stopping time. Then we know that as long as the stopping time has not been hit, the price level is below our trigger price level. 
	* Proof: Take any n. Then $N_n$ is a bounded stopping time, and so $E(Z_{N_n}) = E(Z_1)$. Let $Y_n = Z_{N_n}$. Since $P(N < \infty) = 1$ we know that $N_n \rightarrow N$ as $n \rightarrow \infty$ and since these are integer-valued RVs, this implies that $N_n = N$ for all sufficiently large n, where suff. large is random. Therefore $Y_n \rightarrow Z_N$ as $n \rightarrow \infty$ or $\underset{n \rightarrow \infty}{lim} Y_n = Z_N$. Y is a sequence and $Z_N$ is a single random variable. 
	* The value of the index on the day it crosses our limit value is $Z_N$. Then $Y_n$ is the value of the index on the day it crosses the threshold which could be before $Z_N$ or equal $Z_N$. If it crosses on day 100, then $Y_1$ equals value on the first day etc,..., $Y_{100}$ equals the value of the index on day 100, but then $Y_{101}=Y_{102}=Y_{103}... = Y_{100}$ since we have crossed the threshold. 
	* Moreover by assumption, $|Y_n| = |Z_{N_n}| \leq C$ since $|Z_k| \leq C$ when $k \leq N$ and $N_n \leq N$. Therefore by the bounded convergence theorem, $E(Z_N) = E(\underset{n\rightarrow \infty }{lim} Y_n) = \underset{n\rightarrow \infty }{lim} E(Y_n) = \underset{n\rightarrow \infty }{lim} E(Z_{N_n}) = E(Z_1)$
	* Aside: example of N where there is no such C. Let $X_1,...$ iid N(0,1) and $S_n = \sum_{i=1}^n X_i$. Then $S_0, S_1,...$ is a martingale. Let $N = min\{n: |S_n| \geq 1\}$. Then you know that $|S_n| < 1$ for all n < N but no such guarantee can be given for $n = N$ since the $X_i$'s are unbounded RVs

### Applications
* Example: Suppose that a gambler starts with $a$ dollars in his pocket. At each turn he wins 1 dollar with probability 1/2 and loses with probability 1/2. He sets a target $b > a$ for himself, planning to continue playing until he either reaches $b$ or goes broke. (a,b integers)
	* (1) What is the probability of reaching b before going broke? Let $S_0 = a$ and $S_n = $ dollar worth of the gambler after playing n games. Let $T = min\{n: S_n = 0 \;  or \; b\}$ = stopping time of the gambler. (You can check $S_0, S_1,...$ is a martingale, since it is just a RW shifted by a). Claim: $P(T < \infty) =1$ - note this is not obvious, that you always stop eventually.
		* Proof: Divide up the positive integers into disjoint blocks of length b. If the gambler goes on playing indefinitely (allowing negative dollars, ie. borrowing) then if any block has all wins for the gambler (a block where he wins every turn) then T must happen in that block or before it. Say b is 100 dollars, if there is ever a block where the gambler wins all 100 turns, if his dollar amount at the beginning  $a$ were between 0 -100 then he certainly would have more than $a$ within that block or the stopping time (0 or 100) would have already been hit in a prior block. (Why? Suppose that the gambler wins every toss from step $kb + 1$ to $(k+1)b$, ie. the kth block. Then either (1) $S_{kb} \in [0,b]$. In this case, $S_{(k+1)b} \geq b$ and so $T \leq (k+1)b$ or (2) $S_{kb} \notin [0,b]$ In this case we know that $T \leq kb$ by the definition of T. So in either case $T \leq (k+1)b$) But the chance that this happens in any given block of b bets is $\left(\frac{1}{2}\right)^b = 2^{-b}$ (and not happening $(1-2^{-b})$) so $P($this does not happen in blocks 1,...,k$) \overset{\perp}{=} (1 - 2^{-b})^k$ by independence of blocks. This goes to 0 as k goes to infinity - $P($this never happens$)= 0$. Therefore $P(T = \infty) = 0$ (since T is only infinity when there is no such block).You can think of each block as a toss of a coin - even when there is small chance of flipping heads, given a long enough time horizon you are guaranteed to flip heads in the limit.
		* Next note that if $n \leq T$ then $|S_n| \leq b$ - the winning of the gambler bounded by b. This a random walk with bounded increments. Therefore by the theorem, $E(S_T) = E(S_0) = a$ but $S_T = \begin{cases} b & \text{if gambler reaches b before 0} \\ 0 & else \end{cases}$. The value of the winnings of the gambler at the stopping time is either b or 0.
		* So $E(S_T) = b P(\text{reaching b before 0}) + 0 P(\text{reaching 0 before b}) = b P(\text{reaching b before 0})$. But we now know that $E(S_T) = a$ so $P(\text{reaching b before 0}) = \frac{a}{b}$
		* For example if a gambler starts with 900 dollars and target is 1000, then $P($ reaching taget$) = \frac{900}{1000} = 0.9$ so there is a 90% chance of reaching the target before going broke.
		* We will see this takes a large number of steps and the result is very sensitive to the probabiltiies of winning / losing.
	* (2) What is $E(T)$? Claim: Define $Z_n = (S_n -a)^2 -n$. This sequence $Z_0=0, Z_1,...$ is also a martingale.
		* Aside: Suppose you have a sequence $Z_1,Z_2,...$ and another sequence $X_1,...$ st each $Z_i$ is a function of $X_1,...,X_i$ and $E(Z_{n+1} | X_1,...,X_n) = Z_n$ for each n. Then also we say that $Z_1,...$ is a martingale and all theorems apply.
		* Proof: Expected value given the past $E(Z_{n+1} | X_1,...,X)$? $X_i$ are iid $\pm 1$ representing the wins and losses. So $E(Z_{n+1} | X_1,...,X_n) = E((S_{n+1} - a)^2  - (n+1)| X_1,...,X) = E((X_{n+1} + S_{n} - a)^2  | X_1,...,X) - (n+1)$. Expanding the squared terms and using expectation linearity $ = E(X_{n+1}^2 | X_1,...,X) + 2E(X_{n+1}(S_{n} - a) | X_1,...,X)  + E((S_{n} - a)^2 | X_1,...,X)- (n+1)$. 
		  * Then $E(X_{n+1}^2 | X_1,...,X) = E(X_{n+1}^2) = 1$. 
		  * And given $X_1,...,X_n, \; (S_n -a)$ is a constant so $2E(X_{n+1}(S_{n} - a) | X_1,...,X) = 2(S_{n} - a)E(X_{n+1} | X_1,...,X) = 2(S_{n} - a)E(X_{n+1}) = 0$. 
		  * Finally by similar logic, $E((S_{n} - a)^2 | X_1,...,X) = (S_n - a)^2$. So overall $E(Z_{n+1} | X_1,...,X) = 1 + 0 + (S_n - a)^2 - (n+1) = (S_n -a)^2 -n = Z_n$ so we have a martingale.
		* So if we let $T_n = \begin{cases} T & if \; T \leq n \\ n & else \end{cases}$ then $E(Z_{T_n}) = E(Z_0) = 0$. But $Z_{T_n} = (S_{T_N} - a)^2 - T_n$ by the definition of Z. So $E((S_{T_n}- a)^2) = E(T_n)$. Now $T_n \rightarrow T$ as $ n \rightarrow \infty$ and $T_n$ is an increasing sequence, so by monotone convergence $E(T_n) \rightarrow E(T)$. 
		* Next note that $S_{T_n} \rightarrow S_T$ as $ n \rightarrow \infty$ and $(S_{T_n} - a)^2 \leq b^2$ so by bounded convergence, $E((S_{T_n} -a)^2) \rightarrow E(S_T - a)^2$. Thus $E(S_T -a)^2 = E(T)$. 
		* But we know that $P(S_T = b) = a/b$ and $P(S_T=  0) = 1- a/b$ and thus $E(T) =E(S_T -a)^2 = (b-a)^2P(S_t = b) + (0-a)^2 P(S_T= 0) = (b-a)^2 a/b + a^2 \frac{b-a}{b} = a(b-a)$ So expected time to hit b or go broke $E(T) = a(b-a)$. If a = 900, b = 1000, we saw P(reaching b before 0) = 0.9, but $E(T) = 900(1000-900) = 90,000$. It takes a very long time despite favorable odds for winning b; many oscillating steps to reach 1000.
	* (3) What if the chance of winning at each turn is not exactly 1/2? Say it is $p \neq 1/2$ instead. In Roulette, p=18/38.
		* How to calculate P(reaching b before 0)? In the case p = 1/2, recall that we used the fact that $S_n$ is a martingale to prove that $E(S_T) = E(S_0) = a$ and then deduced the distribution of $S_T$ from this (which is possible since $S_T$ can only take two values 0, b. Otherwise cannot deduce a distribution from an expected value). When $p \neq 1/2,\;S_n$ is not a martingale; here actually $S_n- (2p-1)n$ is a martingale, but that does not help because this expecation equal to zero does not help us get to $E(S_T)$ because we do not know $E(T)$. Instead let $Z = \left(\frac{q}{p}\right)^{S_n}, \;q=1-p$. Claim: $\{Z_n\}_{n \geq1}$ is a martingale 
		* Proof: $E(Z_{n+1} | X_1,...,X_n) = E( \left(\frac{q}{p}\right)^{S_{n+1}} | X_1,...,X_n)$. Now $S_{n+1}  = S_n + X_{n+1}$. So given $X_1,...,X_n,\; \left(\frac{q}{p}\right)^{S_{n}}$ is a constant. So $= \left(\frac{q}{p}\right)^{S_{n}}E(\left(\frac{q}{p}\right)^{X_{n+1}} | X_1,...,X_n)$. Then since $X_{n+1} \perp X_1,...X_n$, say $ = \left(\frac{q}{p}\right)^{S_{n}}E(\left(\frac{q}{p}\right)^{X_{n+1}}) =  \left(\frac{q}{p}\right)^{S_{n}}(\left(\frac{q}{p}\right)P(X_{n+1} = 1) +\left(\frac{q}{p}\right)^{-1}P(X_{n+1} = -1) )   = Z_n$. 
		* As before, let $T_n = min\{T,n\}$ where $T =min\{n: S_n = b ,0\}$ Then $T_n$ is a bounded stopping time and $E(Z_{T_n}) = E(Z_0) = (\frac{q}{p})^a$. We also know that $P(T<\infty) = 1$ (we proved this when p = 1/2, proof here is similar). Thus $Z_{T_n} \rightarrow Z_T$ as $n \rightarrow \infty$. Also since $T_n \leq T$, $0 \leq Z_{T_n} \leq max\{(\frac{q}{p})^0,(\frac{q}{p})^1, ..., (\frac{q}{p})^b \} = max\{1, (\frac{q}{p})^b\} < \infty$ So by the bounded convergence theorem, $E(Z_{T_n}) \rightarrow E(Z_T)$ and $E(Z_T) = (\frac{q}{p})^a$. As before $Z_T$ can only take two values, namely 1 and $(\frac{q}{p})^b$ (Since $S_T$ can only take on 0 or b). Therefore $E(Z_T) = P(Z_T = 1) 1 + P(Z_T = (\frac{q}{p})^b)(\frac{q}{p})^b = 1- P(S_T = b) + P(S_T = b)(\frac{q}{p})^b$ 
		* Therefore $1 - P(S_T = b) + P(S_T = b)(\frac{q}{p})^b = (\frac{q}{p})^a \implies P(S_T =b) = \frac{(\frac{q}{p})^a - 1}{(\frac{q}{p})^b -1 }$ for $q \neq p$. For example if a = 900, b=1000 and p = 18/38, then $P(S_T = b) \approx 0.000027$ - the gambler essentially has no chance of winning now that p is slightly off of 1/2. In the beggining, the situation looks similar to p=1/2 with wins and losses, but later the fluctuations have a slow negative drift, and since it took so long to reach 1000 with p=1/2, the losses will slowly increase and 1000 will be further out of reach.
		* If the gambler is allowed to bet larger amounts than a dollar, there are more optimal strategies. If you have more than 500, bet the remaining amount of money to goal, if less than 500 bet everything you have. Has 88% chance of success with a fair coin. With these roulette odds, it still performs very well. 

### Martingale Varieties
* A sequence $Z_1,...$ is called a **submartingale** if $Z_n \leq E(Z_{n+1} | Z_1,...,Z_n)$ (equality holds if martingale - martingales are submartingales but not conversely). 
	* Example: if $\{Z_n\}$ is a martingale then $\{Z_n^2\}$ is a submartingale. 
	* Proof: $E(Z_{n+1}^2 | Z_1,...,Z_n) = E((Z_{n+1}-Z_n + Z_n)^2 | Z_1,...,Z_n) = E((Z_{n+1}-Z_n)^2 + 2Z_n(Z_{n+1} - Z_n) + Z_n^2 | Z_1,...,Z_n)$ Note that given up to $Z_n$ the RV $Z_n$ becomes a constant so $E(Z_n(Z_{n+1} - Z_n) | Z_1,..,Z_n) = Z_nE(Z_{n+1} | Z_1,...,Z_n) - Z_n^2 = Z_n^2 - Z_n^2 =0$. Therefore $E(Z_{n+1}^2 | Z_1,...,Z_n) = E((Z_{n+1} - Z_n)^2 | Z_1,..,Z_n) + Z_n^2 \geq Z_n^2$.
* **<u>Submartingale Stopping Theorem</u>**: Let $\{X_n\}$ be a submartingale and T be a bounded stopping time (ie. there is a constant n st $T \leq n$ always). Then $ E(X_n)\geq E(X_T) \geq E(X_1)$. 
  * Proof: Exactly the same as for the MST, replacing equalities with inequalities.
* **<u>Submartingale Maximal Inequality</u>**: Let $\{X_n\}$ be a non-negative submartingale, then for any n and any $a > 0, \; P(max\{X_1,...,X_n\} \geq a) \leq \frac{E(X_n)}{a}$
	* Proof: Fix n. Let $N  = \begin{cases} \text{first } i \leq n \text{ st } X_i > a & \text{if such i exists} \\ n & otherwise \end{cases}$ Can check N is a stopping time, moreover $N \leq n$, thus by the submartingale stopping theorem $E(X_N)  \leq E(X_n)$. But $max\{X_1,...,X_n\} > a \implies X_N > a$, since there is some i st $X_i > a$ (Note that $max\{X_1,..,X_n\} > a$ then there is some $i \leq n $ st $X_i > a$ and so N, being the minimum such i, also satisfies $X_N > a$). Thus $P(max\{X_1,...,X_n\} \geq a) \leq P(X_N > a) \leq \frac{E(X_N)}{a} \leq \frac{E(X_n)}{a} $. First inequality bounded by Markov inequality and second by SST. 

### Cauchy Martingales
* Recall Polya's Urn model: An urn contains one white ball and one black ball. Pick a ball at random. Replace it back to the urn together with an extra ball of the same color. Repeat. Let $X_n$ be the proportion of white balls at time n (start at time 1). **Claim**: $\{X_n\}_{n \geq 1}$ is Cauchy WP1 and hence convergent. 
	* Note that we are not claiming anything about the limit; in fact the limit is random.
	* Recall: a sequence of real numbers $x_1,x_2,...$ is called Cauchy if $\forall \epsilon > 0,\; \exists n_0 \geq 1, st\; \forall m,n \geq n_0,\; |x_m - x_n| \leq \epsilon$. After a certain stage, all of the numbers in the sequence are within some epsilon of each other. Important fact: a sequence of real numbers is convergent iff it is Cauchy.
	* This follows from the martingale convergence theorem: Let $\{Z_n\}$ be a martingale with $\underset{n \geq 1}{sup}\; E(Z_n) < \infty$ - many martingales do not satisfy this, such as random walk. For example, the $X_n$ for the Polya Urn model do satisfy this condition, since $0 \leq X_n \leq 1$ and also recall that $X_n$ is a martingale. Then with probability 1, $\{Z_n\}$ is a Cauchy sequence and hence convergent.
	* Will work towards proof: (under slightly stronger assumption that $\underset{n \geq 1}{sup} \;E(Z_n^2) < \infty$, note this also holds for Polya. 
	* We will now show that if $\{Z_n\}$ is a Martingale such that $\underset{n \geq 1}{sup}\; E(Z_n^2) < \infty$ then WP1 $\{Z_n\}$ is a Cauchy sequence. 
	* Step 1:  $E(Z_n^2)$ is an increasing sequence and being bounded has a limit. Proof: Let's prove this with $Z_0 = 0$. We will show that for any $m \leq n,\; E(Z_n - Z_m)^2 = E(Z_n^2) - E(Z_m^2)$ (1). This will imply that $E(Z_n^2) - E(Z_1^2) = \sum_{i=2}^n [E(Z_i^2) - E(Z_{i-1}^2)] = \sum_{i=2}^n E[(Z_i - Z_{i-1})^2]$ (Telescoping sum). This clearly shows that $E(Z_n^2) $ is an increasing sequence. 
		* Let $\mu = \underset{n \rightarrow \infty}{lim} E(Z_n^2)$. Proving eqn (1): $E(Z_n - Z_m)^2 = E((Z_n - Z_{n-1} + Z_{n-1} - Z_m)^2) =  E((Z_n - Z_{n-1} )^2 + 2(Z_n - Z_{n-1})( Z_{n-1}-Z_m) + (Z_{n-1} - Z_m)^2)$. Claim: expected value of the middle term is zero. Then $E( 2(Z_n - Z_{n-1})( Z_{n-1}-Z_m)  | Z_1,...,Z_{n-1}) = 2(Z_{n-1} - Z_m)E(Z_n - Z_{n-1} | Z_1,...Z_{n-1}) = 2(Z_{n-1} - Z_n)(E(Z_n|Z_1,...,Z_{n-1}) - Z_{n-1}) = 0. 
		* Fact: $E(E(X|Y_1,...,Y_n)) = E(X)$. Suppose the RV are discrete, then $ E(E(Z|Y_1,...,Y_n)) = \sum_{y} E(X|Y_1= y_1,...Y_n=y_n)P(Y_1= y_1,...Y_n=y_n) $ Then $ =  \sum_{y} (\sum_x P(X=x|Y_1= y_1,...Y_n=y_n))P(Y_1= y_1,...Y_n=y_n)  = \sum_y \sum_x X P(X=x, Y_1= y_1,...Y_n=y_n)$ and finally $ = \sum_x X \sum_y P(X=x, Y_1= y_1,...Y_n=y_n)=\sum_x X  P(X=x) = E(X) $
		* Since middle term is 0, we can take expectation of both sides to get $E(2(Z_n - Z_{n-1}) (Z_{n-1} - Z_{m})| ) = 0. Thus $E(Z_n - Z_m)^2 = E((Z_n - Z_{n-1})^2 + E(Z_{n-1} - Z_m)^2$. 
		* Continue this way to get $E\left(Z_{n}-Z_{m}\right)^{2}=\sum_{i=m+1}^{n} E\left(Z_{i}-Z_{i-1}\right)^{2}$ In particular $E(Z_n^2) = E\left(Z_{n}-Z_{0}\right)^{2}=\sum_{i=1}^{n} E\left(Z_{i}-Z_{i-1}\right)^{2}$ and $E(Z_m^2) = E\left(Z_{m}-Z_{0}\right)^{2}=\sum_{i=1}^{m} E\left(Z_{i}-Z_{i-1}\right)^{2}$. Thus $E(Z_n^2) - E(Z_m^2) = E(Z_n - Z_m)^2$.
		* Step 2: Take any $m,n \geq 1$. Note that the sequence $M_0,...$ where $M_i = Z_{m+i} - Z_m$ is also a martingale wrt the sequence $((Z_0,...,Z_m),Z_{m+1},Z_{m+2}, ...)$. Why? $E(M_{i+1} | Z_0,...,Z_{m+i}) = E(Z_{m+i+1} - Z_m | Z_0,...,Z_{m+i}) = Z_{m+i} - Z_m = M_i$. So $\{M_i^2\}$ is a submartingale, so by the maximal inequality, $P(\underset{0 \leq i \leq n}{max} \;|Z_{m+i} - Z_m| > \epsilon) = P((\underset{0 \leq i \leq n}{max} \;M_i^2> \epsilon^2)$  bounded by $ \leq \frac{E(M_n^2)}{\epsilon^2} = \frac{E(Z_{m+n} - Z_n)^2}{\epsilon^2} = \frac{E(Z_{m+n})^2 - E(Z_n)^2}{\epsilon^2}$. IF $A_n = \underset{0 \leq i \leq n}{max} \;|Z_{m+i} - Z_m| > \epsilon$ then $A_0 \subset A_1 \subset A_2...$ - increasing events. Therefore $P(\cup_{n=0}^\infty A_n) = \underset{n\rightarrow \infty}{lim} P(A_n)$, as a consequence of the countable additivity of P. But $\cup_{n=0}^\infty A_n = \{|Z_{m+i} - Z_m| > \epsilon\}$ for some $i \geq 0$. Thus $P(|Z_{m+i} - Z_m| >\epsilon) \leq  \underset{n\rightarrow \infty}{lim} \frac{E(Z_{m+n})^2 - E(Z_n)^2}{\epsilon^2} = \frac{\mu - E(Z_m^2)}{\epsilon^2}$.
		* So if we consider the complementary event $B_n = \{|Z_{m+i} - Z_m| \leq \epsilon\}$ has probability $\geq 1 - \frac{\mu - E(Z_m^2)}{\epsilon^2}$. Let $B = \cup_{m=0}^\infty B_m$ then $P(B) \geq P(B_m)$ for all m $\implies P(B) \geq  \underset{m\rightarrow \infty}{limsup}  P(B_m) \geq  \underset{m \rightarrow \infty}{limsup} (1- \frac{\mu - E(Z_m^2)}{\epsilon^2})$. But $E(Z_m^2) \rightarrow \mu$ as $\mu \rightarrow \infty$ so $P(B) \geq 1$ but that means P(B) = 1. So $B = \{\exists m \;st\; |Z_{m+i} - Z_m| \leq \epsilon \forall i \geq 0\}$. But $B \implies \{\exists m \;st\; |Z_{k} - Z_m| \leq \epsilon \text{ and }  |Z_{l} - Z_m| \leq \epsilon\}$. Then $|Z_k - Z_l | \leq |Z_k - Z_m| + |Z_l - Z_m| \leq \epsilon$. Thus $P(C_\epsilon) = 1. Let $C = \cap_{n=1}^\infty C_{1/n} = \{\forall n \geq 1, \exists m \geq 1\; st\; |Z_k - Z_l | \leq 1/n \forall k,l \geq m\}$ Since $P(C_{1/n}) = 1,\; \forall n$ we get P(C) = 1. $C \implies$ the sequence $\{Z_n\}$ is Cauchy and therefore convergent.
*  General Case: Take any martingale $Z_n$ st $ \underset{n \geq 1}{sup} E(Z_n^2) < \infty$ . Let $a = E(Z_1)$. We proved that $E(Z_n) = E(Z_1)$. Define $M_n = Z_n -a,\; n \geq 1$, Let $M_) =0$. Then $\{M_n\}$ is also a martingale because $E(M_{n+1} | Z_1,...,Z_n) = E(Z_{n+1} - a | Z_1,...,Z_n) = Z_n - a = M_n$ .We also have $E(M_1 | M_0) = E(M_1) = E(Z_1) - a= 0 = M_0$. Note also that $E(M_n^2)  =E(Z_n - a)^2$, then using $(x + y)^2 \leq 2x^2 + 2y^2$ we get $\leq 2E(Z_n^2) + 2a^2 \implies $ \underset{n \geq 1}{sup} E(M_n^2) < \infty$. Thus $\{M_n\}$ is Cauchy WP1 and therefore so is $\{Z_n\}$. 
*  Example: If $X_n$ is a fraction of white balls at time n in Polya Urn, then $X_n$ converges WP1 as $n \rightarrow \infty$. The limit is random. Actually the limit is a uniform $[0,1]$. How could we prove this? Proof by induction that for any n (process starts at time 1 with 1 white and 1 black), $X_n \sim unif(\{\frac{1}{n+1}, \frac{2}{n+1}, ..., \frac{n}{n+1}\})$

### Concentration Inequalities

* <u>**Azuma - Hoeffding Inequality**</u>: Let $Z_0,Z_1,...$ be a martingale and let $\mu = E(Z_0)$. Suppose also that there is a non-random, fixed constant c st $|Z_i - Z_{i-1}| \leq c \; \forall i$. Then for any n and any $t \geq 0$ the $P(|Z_n - \mu| \geq t) \leq 2 e^{-\frac{t^2}{2nc^2}}$.
	* A bounded difference martingale allows us to say something about the fluctuation of the nth martingale.
	* We will prove that $P(Z_n - \mu \geq t) \leq e^{-\frac{t^2}{2nc^2}}$. Same argument applied $-Z_n$ will show that $P(Z_n - \mu \leq -t) \leq e^{-\frac{t^2}{2nc^2}}$. Combining we get $P(|Z_n - \mu| \geq t) \leq 2 e^{-\frac{t^2}{2nc^2}} \leq P(Z_n - \mu \geq t) + P(Z_n - \mu \leq -t) \leq 2 e^{-\frac{t^2}{2nc^2}}$.
	* First step: show that for any $\theta > 0$, $E(e^{\theta(Z_n - \mu)}) \leq e^{nc^2\theta^2/2}$. Proof: $E(e^{\theta(Z_n - \mu)}) =E( E(e^{\theta(Z_n - \mu)}|Z_1,...,Z_{n-1}))$. Now $E(e^{\theta(Z_n - \mu)}|Z_1,...,Z_{n-1}) = E(e^{\theta(Z_{n} -Z_{n-1}}e^{\theta(Z_{n-1} - \mu)}|Z_1,...,Z_{n-1}) = e^{\theta(Z_{n-1} - \mu)}E(e^{\theta(Z_{n} -Z_{n-1}}|Z_1,...,Z_{n-1}) $. Given $Z_1,...,Z_{n-1}$ the conditional expectation of $Z_n - Z_{n-1}$ is 0. Also $|Z_n - Z_{n-1}| \leq c$. So by the following lemma, we get $E(e^{\theta(Z_{n} -Z_{n-1}}|Z_1,...,Z_{n-1}) \leq e^{\theta^2c^2/2}$.
	* **Lemma**: If X is a RV st $E(X) = 0$ and $|X| \leq c$ then E(e^{\theta x}) \leq e^{\theta^2c^2/2}$
		* Proof: The function $f(x) = e^{\theta X}$ is convex on $\R$ meaning that $f''(x) \geq 0$ everywhere. This means that $f'(x)$ is an increasing function of x. So f is constantly bending upwards. Such functions have the property that for any x,y and for any $t \in [0,1],\; f(tx + (1-t)y) \leq tf(x) +(1-t) f(y)$, ie a midpoint between x-axis values x and y, the value of the the point on f(x) is bounded above by the line connecting f(y) and f(x) (sensible since curve sags below straight lines). 
		* Take any $x \in [-c, c]$, write $x = t(-c) + (1-t) c$ where $t = \frac{c-x}{2c},\; \in [0,1]$. So $e^{\theta x} = f(t(-c) + (1-t)c) \leq tf(-c) + (1-t) f(c) = \frac{c-x}{2c}e^{-c\theta} + \frac{c+x}{2c}e^{c\theta}$. This holds if we put X in place of x so $E(e^{\theta X}) \leq E(\frac{c-X}{2c}e^{-c\theta} + \frac{c+X}{2c}e^{c\theta})$. But $E(X) = 0$. So $E(e^{\theta X}) \leq \frac{1}{2}e^{-c\theta} + \frac{1}{2}e^{c\theta} = cosh(c\theta$. (Fact: $cosh(x) \leq e^{x^2/2})$ using series expansion.)
		* Thus $E(e^{\theta(Z_n - Z_{n-1})}| Z_1,...,Z_{n-1})\ leq e^{\theta^2c^2/2}$ which gives us $E(e^{\theta(Z_n - \mu)}| Z_1,...,Z_n) \leq e^{\theta(Z_{n-1} - \mu)}e^{\theta^2c^2/2}$. Taking expectations, $E(e^{\theta(Z_n - \mu)}) \leq E(e^{\theta(Z_{n-1} - \mu)})e^{\theta^2c^2/2}$ and continue by backward induction.
		* Thus we end up proving $E(e^{\theta(Z_n - \mu)}) \leq e^{n\theta^2c^2 /2}$. For any t > 0, $P(Z_n - \mu \geq t) = P(e^{\theta(Z_n - \mu)} > e^{\theta t}) \leq e^{-\theta t}E(e^{\theta(Z_n - \mu)})$ by markov inequality. Then $\leq e^{-\theta t + n\theta^2c^2/2}$. Given t find optimal $\theta, \; \hat{\theta} = \frac{t}{nc^2}$. Pluggin this in we get $P(Z_n - \mu \geq t ) \leq e^{-t^2/(2nc^2)}$
* <u>**Bounded Difference Inequality**</u>: Let $X_1,...,X_n$ be independent RV (or even random vectors of varying dimensions). Let $y = f(X_1,...,X_n)$ be some function of $X_1,...,X_n$ with the following property: $|f(x_1,...,x_n) - f(x_1,...,x_{i-1}, x_i^\prime, x_{i+1},...,x_n)| \leq c$ for any $x_1,...,x_n$ any i, any $x_i^\prime$. Then $\forall t > 0,\; P(|y-E(y| \geq t) \leq 2e^{-t^2/2nc^2}$.
	* If you change one coordinate, the value of the function can change by at most c, then this inequality applies
	* Let $Z_i = E(Y|X_1,...,X_i)$ for $1 \leq i\leq n,\; Z_0 = E(Y)$. Then $\{Z_i\}$ is a martingale sequence since $E(Z_i | X_1,...,X_{i-1}) = Z_{i-1}$.
	* Note $Z_n = E(Y|X_1,...,X_n) = Y$. Claim: $|Z_i - Z_{i-1}| $ is always bounded by c for any i.  Here we use independence of $X_1,...,X_n$. 
	* Proof: Let $f_i(x_1,...,x_i) = E(Y|X_1,..,X_i)$. Since $Y = f(X_1,...,X_n)$ and X's are independent, $E(Y|X_1=x_1,...,X_i=x_i) = E(f(x_1,...,x_i, X_{i+1},...,X_n))$ (Substituting in specific values does not affect the future RVs due to independence. Why? $E(Y|X_1=x_1,...,X_i=x_i) = E(f(X_1,...,X_n)| X_1=x_1,...,X_i=x_i) $ and expanding $= \sum_{x_{i+1},...,X_n} f(x_1,...,x_n) P(X_{i+1} = x_{i+1},...,X_n=x_n | X_1=x_1,...,X_i=x_i) \\= \sum  f(x_1,...,x_n) P(X_{i+1} = x_{i+1},...,X_n=x_n)$ by independence.)
	* Claim: for any $X_1,...,X_{i+1}$ the $|f_i(X_1,...,X_i) - f_{i+1}(X_1,...,X_{i+1})| \leq c$. Proof: $|f_i(X_1,...,X_i) - f_{i+1}(X_1,...,X_{i+1})| = |E(f_i(x_1,...,x_i,X_{i+1},...,X_n) -  E(f_i(x_1,...,x_i,x_{i+1}, X_{i+2}...,X_n))|$. Then $=  |E(f_i(x_1,...,x_i,X_{i+1},...,X_n) -  f_i(x_1,...,x_i,x_{i+1}, X_{i+2}...,X_n))|$ which is $\leq E|(f_i(x_1,...,x_i,X_{i+1},...,X_n) -  f_i(x_1,...,x_i,x_{i+1}, X_{i+2}...,X_n))|$. The vectors $(x_1,...,x_i,X_{i+1},...,X_n),\;(x_1,...,x_i,x_{i+1}, X_{i+2}...,X_n)$ differ only in coordinate i +1. Thus the above quantity is bounded by c.
	* Therefore by the A-H inequality, $P(|Z_n - E(Z_n)| \geq t) \leq 2e^{-t^2/2nc^2}$ but $Z_n = Y$.

### Applications
* Bin packing: You have an infinite number of bins, each of capacity 1. You have m items with iid weights $X_1,...,X_m$, with each weight between 0 and 1. Let L be the minimum number of bins required to pack all the items. We do not know the distribution, just that each item can fit into an empty bin. Note: L is random. Find L.
	* Consider L as a function of the weights $X_1,..,X_m$. If you change exactly one weight, keeping all else constant, you may need at most 1 extra bin to pack all the weights. So if L' is the new value if L, then $L' \leq L + 1$. But by the same logic $L \leq L' + 1$; therefore $|L- L'| \leq 1$. Therefore here c = 1, and so by the bounded difference inequality, $P(|L - E(L)| \geq t) \leq 2e^{-t^2/2m}$ since m is the number of independent RVs.  This becomes friendlier if we replace t by $x\sqrt{m}$ which gives $P(|L - E(L)| \geq x\sqrt{m}) \leq 2e^{-x^2/2}$ . Thus L fluctuates around its EV by at most $O(\sqrt{m})$. Eg. $Var(L) = E((L- E(L))^2) = \int_0^\infty P(|L - E(L) |^2\geq t)  dt \leq 4m$. 
	* We can see why these are called concentration inequalities - RV is concentrated around its EV. Note that $L \geq \sum X_i$ so if $E(X_i) \neq 0$, then $E(L) \geq m E(X_1)$ so the concentration inequality shows that $\frac{L}{E(L)} \overset{P}{\rightarrow} 1$ in probability as $m \rightarrow \infty$ (say for $L = L_m$). 
	* In our example, $E(L) \geq m E(X_1) \implies P(|\frac{L}{EL} - 1| > \epsilon) = P(|L- E(L)| > \epsilon E(L)) \leq 2e^{\epsilon^2E(L)^2}{2m} \leq 2e^{\epsilon^2m^2 E(X_1)^2}{2m} = 2e^{\epsilon^2m E(X_1)^2}{2} \rightarrow 0$ as $m \rightarrow \infty,\; \forall \epsilon > 0$.
* Chromatic Number of a Random Graph: A simple graph consists of a set of vertices, some of which are connected to each other by edges. The chromatic number of such a graph is the minimum number of colors required to color the vertices such that no two vertices that are connected by an edge receive the same color. 
	* Consider a random graph on n vertices, defined as follows: for any two vertices, put an edge between them with probability 1/2 independently of each other. This is equivalent to picking a graph uniformly at random from the set of all graphs on these n vertices. Why? There are $2^{{n \choose 2}}$ graphs since  ${n \choose 2}$ possible edges and each be present or absent (binary variable on or off). The random graph defined above has probability = $2^{-{n\choose 2}} $ of being any of these graphs (certain combination of switching every possible edge on or off, and they are present independently). Let $G_n$ denote this random graph. This is actually an instance of the Erdos - Renyi G(n, 1/2) random graph. Let $\chi_n$ be the chromatic number of $G_n$. What is the behavior of $\chi_n$ when n is large?
	* One can show that $E(\chi_n)$ behaves like $\frac{n}{2log_2n}$ when n is large. What is the magnitude of $|\chi_n - E(\chi_n)|$? Let $X_1$ = set of edges from vertex 1 to vertices 2,...,n. $X_2$ = set of edges from vertex 2 to vertices 3,...,n, etc. Finally $X_{n-1}$ = set of edges from vertex n-1 to vertex n. Then $X_1,X_2,...,X_{n-1}$ are independent (not iid), since we are never counting the same edge twice. Now $\chi_n$ is a function of $X_1,...,X_{n-1}$. If one $X_i$ is changed, then it changes the edges coming out of exactly one vertex. So $\chi_n^\prime \leq \chi_n + 1$ - at most you have to change the color of this one vertex. Similarly, $\chi_n \leq \chi_n^\prime + 1 \implies |\chi_n - \chi_n^\prime| \leq 1$ so by the bounded difference inequality $P(\chi_n - E(\chi_n)| \geq t) \leq 2e^{-t^2/2(n-1)}$. Again this shows that $\chi_n - E(\chi_n)$ is typically of order $\sqrt{n}$. In particular, $\frac{\chi_n}{E(\chi_n)} \rightarrow 1$ in probability as $n \rightarrow \infty$. 

## Brownian Motion
* Foundation of continuous time stochastic processes. 
* Standard Brownian Motion is a random continuous function B from $[0,\infty) \rightarrow \R$ satisfying the following properties:
	* B(0) = 0
	* For any $0 \leq s \leq t$ B(t) - B(s) $\sim N(0, t-s)$
	* For any $0 \leq t_1 \leq t_2 \leq ... \leq t_n$ (any n), the increment $B(t_1), B(t_2) - B(t_1), ....,B(t_n) - B(t_{n-1})$
* The existence / uniqueness of the probability distribution on the function space will have these properties, those that share these properties are the same distribution
* Interpret $B(t)$ as the location of a randomly moving particle at time t when it starts from 0. 
* Incidentally, if you have any random process in continuous time that moves continuously (not like PP that moves at discrete jumps) and has independent increments, then the increments must necessarily be normal RVs. This is a consequence of CLT. Thus the normality assumption is relatively weak. 
* The variance of the normal is proportional to the length of the interval because we are dealing with homogeneous jumps - a linear process. 
* <u>**Theorem**</u>: WP1 B has no point of differentiability 
* <u>**Theorem**</u>: WP1 there is no interval in which B is increasing or decreasing. 
* <u>**Theorem**</u>: The set of local maxima/minima of B is countable and dense in $[0,\infty)$. 
* On a computer, cannot really simulate a continuous function, so discretize the real line and apply the 2nd and 3rd properties. Generate independent normal RVs for the increments and then connect them together
* Brownian motion is a scaling limit of random walk. More precisely, let $X_1,X_2,...$ be iid RVs with mean 0 and variance 1. For each n, let $S_n = \sum_{i=1}^n X_i,\;S_0=0$. Take any n, define a random continuous function from $[0,\infty) \rightarrow \R$ as follows: if $t=\frac{k}{n}$ for some integer k, let $B_n(t) = \frac{1}{\sqrt{n}}\sum_{i=1}^k X_i = \frac{S_k}{\sqrt{n}}$ (random walk scaled by root n). If t is between k/n and (k+1)/n, use linear interpolation. Then **Dansker's Theorem** says that the sequence of random continuous functions $\{B_n\}$ converges in distribution to standard brownian motion B as $n \rightarrow \infty$. This means that for any continuous $f: C[0,\infty) \rightarrow \R$, the sequence of RVs $f(B_n)$ converges in distribution to f(B) as $n \rightarrow \infty$.
* Example: define a map $f: C[0,\infty] \rightarrow \infty$ for $ C[0,\infty]$ = set of all continuous functions from $[0,\infty]$ to R. $f(\phi) = \underset{0 \leq t \leq 1}{max} \phi(t)$. Take any continuous function, take its max on the domain, that is a continuous map from 0, infty to R. Can show that f is continuous. Now note that $f(B_n) = \frac{1}{\sqrt{n}} \underset{0 \leq t \leq 1}{max} B(t)$. So Dansker tells us that $\frac{1}{\sqrt{n}} \underset{0 \leq t \leq 1}{max} S_i$ converges in distribution to $ \underset{0 \leq t \leq 1}{max} B(t)$. Separately we can show that $\underset{0 \leq t \leq 1}{max} B(t)$ has the same distribution as $|Z|$ where $Z \sim N(0,1)$. Thus, for any sequence of iid RVs $X_1,X_2,...$ mean 0, var 1; if we define $S_0=0$ and $S_n= \sum_{i=1}^n X_i$ for all n, then as $n \rightarrow \infty$, $\frac{1}{\sqrt{n}} \underset{0 \leq t \leq 1}{max} S_i \overset{d}{\rightarrow} |Z|$. This is a weird result, taking the maximum prevents the ability to use CLT, so this is the only way to prove this. 
* **Markov Property of Brownian Motion**: Let B be standard Brownian motion. Take any $s \geq 0$. Let $W(t) = B(s+t) - B(s),\; \forall t \geq 0$. Then W is also a standard BM and is independent of $(B_t)_{0 \leq t \leq s}$
	* Taking BM up to time s, looking at the future, subtracting off the history of time s, is independent of what happened up to time s. 
	* Reason: for any $0 \leq s_1 \leq s_2 \leq ... \leq s_n \leq s$ and any $0 \leq t_1 \leq ... \leq t_m$ one can prove using the independent increments property that the random vectors $(B(s_1),...,B(S_n))$ and $(W(t_1),...,W(t_n))$ are independent. Increments are independent so we can obtain the B sequence and W using different sets of increments and this leads to the vector independence. Since this holds for all choices of $0 \leq s_1 \leq ... \leq s_n \leq s$ and  $0 \leq t_1 \leq ... \leq t_m < \infty$ we can then use measure theory to deduce that the processes $(B(t))_{0 \leq t \leq s} ,\; W((t))_{t \geq 0}$ are independent. 
* Other Properties: 
	* **Scale Invariance**: For any $c > 0$ if we define $W(t) = c^{-1/2}B(ct)$ then W is again standard BM
	* If B is a standard BM, so is -B
	* **Time Inversion**: If B is standard BM and we define W as $W(0) = 0$ and $W(t) = tB(1/t) $ for t > 0, that is again Std BM.
		* Proof: Note $W(0) = 0$ by defn. Take any $0 < s \leq t$ then $W(t) - W(s) = t B(1/t) - s B(1/s)$. Then note that for any $u,v \in [0,\infty],\; u\leq v,\; Cov(B(u), B(v)) = Cov(B(u), B(v) - B(u) + B(u)) = Cov(B(u), B(v) - B(u) ) + Var(B(u))$. The first cov is zero since B(u) and B(v) - B(u) are independent by indep of increments. Also Var(B(u)) = u since $B(u) = B(u) - B(0) \sim N(0,u)$. So if $ u\leq v,\; Cov(B(u) , B(v)) = u$.
		* Conversely if a process $(X_t)$ is such that any $(X(t_1),...,X(t_n))$ is jointly normal and $Cov(X(s),X(t)) = s$ whenever $s \leq t$ one can show by calculating covariances that the process has the independence of incremements property. As long as you have Gaussians, cov = 0 implies RV independence. 
		* Thus $W(t) - W(s) \sim N(0, var=?)$. So $\\Var(W(t) - W(s)) = Var( t B(1/t) - s B(1/s)) \\= t^2 Var(B(1/t)) + s^2 Var(B(1/s) - 2tsCov(B(1/t), B(1/s)) \\= t^2(1/t) + s^2 (1/s) - 2ts (1/t) = t - s$
		* The independent increments of W follow similarly by calculating covariances.
* We did not prove W is continuous - why? $W(T) = tB(1/t), \; t > 0,\; W(0) = 0$. W is obviously continuous at every t > 0 - continuous transform of continuous function. What about continuity at 0? We have to show that $tB(1/t) \rightarrow 0,\; t \rightarrow 0$. This is the same as showing $\frac{B(s)}{s} \rightarrow 0,\; s \rightarrow \infty$ - this is called the **Law of Large Numbers for BM**.
* Note that $B(1),B(2) - B(1),...$ are iid N(0,1) RVs so $\frac{B(n)}{n} = \frac{1}{n} \sum_{i=1}^n (B(i) - B(i-1)) \overset{a.s.}{\rightarrow} 0,\; n \rightarrow \infty$ by LLN but more work is needed to show that $\frac{B(s)}{s}\rightarrow 0,\; s \rightarrow \infty$ since in this case we are not going through the integers.
* **Stopping Time**: A RV T taking value in $[0 ,\infty]$ is called a stopping time for BM if for any t, the occurrence or non-occurrence of the event $\{T \leq t\}$ is determined by the values of $(B(s); s \in [0,t])$. If you know the value of the BM up to time t, you can tell the occurrence of T. 
	* Example: Let $T= inf\{t:\;B(t) = a\}$ (a > 0 is given). Then T is a stopping time. Looking at the BM up to time t, you can determine if a has been crossed.
	* Let  $T= inf\{t:\;B(t) \neq (a,b)\}$ for $(a < 0 < b)$ then T is a stopping time.
	* Let $T = sup\{t \in [0,1]:\; B(t) = 0\}$. Then T is not a stopping time - this requires looking at the future, though proving it is not a stopping time is difficult. 
	* Let $T = sup\{t \geq 0:\; B(t) = t\}$ then T is not a stopping time. There will be a last time that B(t) hits t, since B(t) goes to 0 by LLN. But it requires future knowledge
* **Adaptive Process**: A stochastic process $(X_t)$ is said to be adapted to a BM B if $\forall t, X(t)$ is a function of $(B(s))_{s\leq t}$ - ie it is BM up to the given time. An adapted process is called a martingale if $\forall s \leq t,\;E(X_t | (B(u)_{u \leq s})) = X(s)$ and $E|X_t| < \infty,\;\forall t$. This is just like the discrete case; looking at the BM up to time s, you just get the value of the process X at time s.
	* Example: B itself is a martingale adapted to B
		* Proof: $s \leq t,\; E(B(t) | (B(u))_{u \leq s}) =E(B(t) - B(s) + B(s) | (B(u))_{u \leq s})  = E(B(t) - B(s)  | (B(u))_{u \leq s}) + B(s)$ but by the Markov property $B(t) - B(s) \perp   (B(u))_{u \leq s}$ with independent increments. So $ E(B(t) - B(s)  | (B(u))_{u \leq s}) = E(B(t) - B(s)) = 0$ Since $B(t) - B(s) \sim N(0,t-s)$. Thus $E(B(t) | (B(u))_{u \leq s}) = B(s)$
	* Example: Let $X(t) = B(t)^2 - t$ then $(X(t))_{t \geq 0}$ is a martingale adapted to B. 
		* Proof: Take $s \leq t,\; E(B(t)^2 - t |  (B(u))_{u \leq s}) = E(B(t) - B(s) + B(s)^2  | (B(u))_{u \leq s}) -t$. Then $E((B(t) - B(s))^2 + 2B(s)(B(t) - B(s)) + B(s)^2 |  (B(u))_{u \leq s}) -t$. Evaluating separately, $B(t) - B(s) \perp (B(u))_{u \leq s},\; \sim N(0,t-s)$. So $E((B(t) - B(s))^2| (B(u))_{u \leq s})=E((B(t) - B(s))^2) = t-s$. Next given $(B(u))_{u \leq s}$, B(s) is just a constant. So $E(2B(s)(B(t) - B(s)) | (B(u))_{u \leq s}) = 2B(s)E((B(t) - B(s)) | (B(u))_{u \leq s}) = 0$. Finally, $E(B(s))^2| (B(u))_{u \leq s}) = B(s)^2$ (since just a constant). So $ E(B(t)^2 - t |  (B(u))_{u \leq s})  = t-s + 0 + B(s)^2$ and so $E(X(t) |    (B(u))_{u \leq s}) = t-s + B(s)^t -t = B(s)^t -s = X(s) \implies $ martingale. 
		* In fact you can find a polynomial of B(t) of any degree that is a martingale.
	* Example; Exponential family of Martingales: For any $\lambda \in \R$ the process $X(t) = e^{\lambda B(t) - \frac{\lambda^2}{2}t}$ is a martingale adapted to B.
* <u>**MST for Continuous Time**</u>: 